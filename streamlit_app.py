"""
Streamlit RAG Book Recommendation Chatbot
AI ê¸°ë°˜ ë„ì„œ ì¶”ì²œ ì±—ë´‡ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
"""

import streamlit as st
from src.config import Config
from src.data.document_processor import DocumentProcessor
from src.data.vector_store import VectorStoreManager
from src.core.rag_agent import RAGAgent
from src.core.orchestrator import AmbiguityAwareOrchestrator


# Page configuration
st.set_page_config(
    page_title="AI ë„ì„œ ì¶”ì²œ ì±—ë´‡",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="collapsed",  # ì‚¬ì´ë“œë°”ë¥¼ ê¸°ë³¸ì ìœ¼ë¡œ ìˆ¨ê¹€
)


@st.cache_resource
def initialize_rag_system():
    """
    Initialize RAG system components with caching.
    This ensures the system is loaded only once and reused across sessions.
    """
    try:
        with st.spinner("RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘..."):
            # Setup environment
            Config.setup_environment()

            # Initialize components
            doc_processor = DocumentProcessor()
            vectorstore_manager = VectorStoreManager()

            # Load or create vector store
            if vectorstore_manager.exists():
                vectorstore_manager.load_vectorstore()
                chunks, original_docs = doc_processor.process()
            else:
                chunks, original_docs = doc_processor.process()
                vectorstore_manager.create_vectorstore(chunks, save=True)

            return vectorstore_manager, True, None

    except Exception as e:
        return None, False, str(e)


def initialize_session_state():
    """Initialize Streamlit session state variables."""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "agent" not in st.session_state:
        st.session_state.agent = None
    if "orchestrator" not in st.session_state:
        st.session_state.orchestrator = None
    if "awaiting_clarification" not in st.session_state:
        st.session_state.awaiting_clarification = False
    if "system_ready" not in st.session_state:
        st.session_state.system_ready = False
    if "config_changed" not in st.session_state:
        st.session_state.config_changed = False
    if "use_orchestrator" not in st.session_state:
        st.session_state.use_orchestrator = True  # Default to new orchestrator
    if "include_purchase_links" not in st.session_state:
        st.session_state.include_purchase_links = True  # Default to include links

    # Initialize config values in session state
    if "use_mmr" not in st.session_state:
        st.session_state.use_mmr = Config.USE_MMR
    if "use_reranking" not in st.session_state:
        st.session_state.use_reranking = Config.USE_RERANKING
    if "use_adaptive_k" not in st.session_state:
        st.session_state.use_adaptive_k = Config.USE_ADAPTIVE_K
    if "default_k" not in st.session_state:
        st.session_state.default_k = Config.DEFAULT_K
    if "mmr_lambda" not in st.session_state:
        st.session_state.mmr_lambda = Config.MMR_LAMBDA
    if "selected_model" not in st.session_state:
        st.session_state.selected_model = Config.CHAT_MODEL_NAME


def display_chat_messages():
    """Display chat message history."""
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])


def process_user_query(user_query: str, agent: RAGAgent = None, orchestrator: AmbiguityAwareOrchestrator = None):
    """
    Process user query and generate response.

    Args:
        user_query: User's question
        agent: RAGAgent instance (legacy mode)
        orchestrator: AmbiguityAwareOrchestrator instance (new mode)

    Returns:
        Tuple of (response_text, error, result_dict)
    """
    try:
        if orchestrator is not None:
            # Use new orchestrator
            if st.session_state.awaiting_clarification:
                # This is a clarification response
                result = orchestrator.process_clarification_response(user_query)
            else:
                # This is a new query
                # Pass history excluding the current message (which was just appended)
                chat_history = st.session_state.messages[:-1]
                result = orchestrator.process_query(
                    user_query,
                    chat_history=chat_history,
                    include_links=st.session_state.include_purchase_links
                )

            # Check if needs clarification
            if result["needs_clarification"]:
                st.session_state.awaiting_clarification = True
                response_text = result["clarification_question"]
            else:
                st.session_state.awaiting_clarification = False
                response_text = result["response"]

            return response_text, None, result

        elif agent is not None:
            # Use legacy agent
            response = agent.query(user_query, verbose=False, use_history=True)
            response_text = agent.get_response_text(response)
            return response_text, None, None

        else:
            return None, "No agent or orchestrator available", None

    except Exception as e:
        return None, str(e), None


def apply_config_changes():
    """Apply config changes to Config class and recreate agent/orchestrator."""
    # Config globals are NOT modified anymore to ensure session isolation.
    # Instead, we pass the local config to the instances.

    # Recreate based on mode
    if st.session_state.system_ready:
        if st.session_state.use_orchestrator:
            # Create config dict for current session
            retrieval_config = {
                "use_mmr": st.session_state.use_mmr,
                "use_reranking": st.session_state.use_reranking,
                "use_adaptive_k": st.session_state.use_adaptive_k,
                "mmr_lambda": st.session_state.mmr_lambda
            }
            
            # Create new orchestrator instance with session config
            new_orchestrator = AmbiguityAwareOrchestrator(
                st.session_state.vectorstore_manager,
                model_name=st.session_state.selected_model,
                k=st.session_state.default_k,
                verbose=False,
                retrieval_config=retrieval_config
            )
            st.session_state.orchestrator = new_orchestrator
        else:
            # Legacy Agent support - warning
            # RAGAgent might still rely on global config in some places, 
            # but we are moving towards Orchestrator. 
            # For now, we recreate it but it might still read global defaults unless refactored.
            
            # Save current chat history
            old_chat_history = []
            if st.session_state.agent:
                old_chat_history = st.session_state.agent.chat_history.copy()

            # Create new agent instance
            new_agent = RAGAgent(
                st.session_state.vectorstore_manager,
                model_name=st.session_state.selected_model,
                k=st.session_state.default_k,
                use_advanced_search=any(
                    [st.session_state.use_mmr, st.session_state.use_reranking, st.session_state.use_adaptive_k]
                ),
            )
            # Force recreation
            new_agent.create_agent(verbose=False, force_recreate=True)
            new_agent.chat_history = old_chat_history
            st.session_state.agent = new_agent

    st.session_state.config_changed = False


def sidebar_settings():
    """Display sidebar with system settings and information."""
    with st.sidebar:
        st.title("âš™ï¸ ì„¤ì •")

        if st.session_state.system_ready:
            st.success("âœ… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")

            # ê¸°ë³¸ ì„¤ì • (í•­ìƒ í‘œì‹œ)
            with st.expander("ğŸ§  Agent ëª¨ë“œ", expanded=True):
                use_orchestrator = st.checkbox(
                    "Ambiguity-Aware Orchestrator ì‚¬ìš©",
                    value=st.session_state.use_orchestrator,
                    help="ëª¨í˜¸í•œ ì§ˆë¬¸ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ìƒˆë¡œìš´ Agent"
                )
                if use_orchestrator != st.session_state.use_orchestrator:
                    st.session_state.use_orchestrator = use_orchestrator
                    st.session_state.config_changed = True
                    st.session_state.awaiting_clarification = False

                if st.session_state.use_orchestrator:
                    st.caption("ğŸ†• ëª¨í˜¸í•œ ì§ˆë¬¸ ìë™ ê°ì§€ ë° ëª…í™•í™”")
                else:
                    st.caption("ğŸ“š í‘œì¤€ RAG Agent")

            # ì¶œë ¥ ì˜µì…˜
            with st.expander("ğŸ“‹ ì¶œë ¥ ì˜µì…˜", expanded=False):
                include_links = st.checkbox(
                    "êµ¬ë§¤ ë§í¬ í¬í•¨",
                    value=st.session_state.include_purchase_links,
                    help="ì¶”ì²œ ê²°ê³¼ì— Google ì‡¼í•‘, YES24, ì•Œë¼ë”˜ êµ¬ë§¤ ë§í¬ ì¶”ê°€"
                )
                if include_links != st.session_state.include_purchase_links:
                    st.session_state.include_purchase_links = include_links

            # ëª¨ë¸ ì„¤ì •
            with st.expander("ğŸ¤– ëª¨ë¸ ì„¤ì •", expanded=False):
                model_options = list(Config.AVAILABLE_MODELS.keys())
                model_values = list(Config.AVAILABLE_MODELS.values())

                # Find current model index
                try:
                    current_index = model_values.index(st.session_state.selected_model)
                except ValueError:
                    current_index = 0

                selected_model_name = st.selectbox(
                    "ì±„íŒ… ëª¨ë¸",
                    options=model_options,
                    index=current_index,
                    help="ì‚¬ìš©í•  LLM ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
                    label_visibility="collapsed"
                )

                new_model = Config.AVAILABLE_MODELS[selected_model_name]
                if new_model != st.session_state.selected_model:
                    st.session_state.selected_model = new_model
                    st.session_state.config_changed = True

                st.caption(f"í˜„ì¬: {selected_model_name}")

            # ê²€ìƒ‰ ì„¤ì •
            with st.expander("ğŸ” ê²€ìƒ‰ ì„¤ì •", expanded=False):
                new_k = st.slider(
                    "ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ (K)",
                    min_value=1,
                    max_value=10,
                    value=st.session_state.default_k,
                    help="ê²€ìƒ‰ ì‹œ ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜",
                )
                if new_k != st.session_state.default_k:
                    st.session_state.default_k = new_k
                    st.session_state.config_changed = True

                st.markdown("**ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥**")

                # MMR setting
                use_mmr = st.checkbox(
                    "MMR (ë‹¤ì–‘ì„± ê²€ìƒ‰)",
                    value=st.session_state.use_mmr,
                    help="ê²€ìƒ‰ ê²°ê³¼ì˜ ë‹¤ì–‘ì„±ì„ ë†’ì…ë‹ˆë‹¤",
                )
                if use_mmr != st.session_state.use_mmr:
                    st.session_state.use_mmr = use_mmr
                    st.session_state.config_changed = True

                # MMR Lambda setting (only if MMR is enabled)
                if use_mmr:
                    mmr_lambda = st.slider(
                        "MMR Lambda",
                        min_value=0.0,
                        max_value=1.0,
                        value=st.session_state.mmr_lambda,
                        step=0.1,
                        help="0=ë‹¤ì–‘ì„± ìš°ì„ , 1=ê´€ë ¨ì„± ìš°ì„ ",
                    )
                    if mmr_lambda != st.session_state.mmr_lambda:
                        st.session_state.mmr_lambda = mmr_lambda
                        st.session_state.config_changed = True

                # Reranking setting
                use_reranking = st.checkbox(
                    "Reranking (ë² ìŠ¤íŠ¸ì…€ëŸ¬ ê³ ë ¤)",
                    value=st.session_state.use_reranking,
                    help="ë² ìŠ¤íŠ¸ì…€ëŸ¬ ìˆœìœ„ë¥¼ ê³ ë ¤í•˜ì—¬ ì¬ì •ë ¬í•©ë‹ˆë‹¤",
                )
                if use_reranking != st.session_state.use_reranking:
                    st.session_state.use_reranking = use_reranking
                    st.session_state.config_changed = True

                # Adaptive K setting
                use_adaptive_k = st.checkbox(
                    "Adaptive K (ìë™ ì¡°ì ˆ)",
                    value=st.session_state.use_adaptive_k,
                    help="ìœ ì‚¬ë„ì— ë”°ë¼ ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ë¥¼ ìë™ ì¡°ì ˆí•©ë‹ˆë‹¤",
                )
                if use_adaptive_k != st.session_state.use_adaptive_k:
                    st.session_state.use_adaptive_k = use_adaptive_k
                    st.session_state.config_changed = True

                # Apply button
                if st.session_state.config_changed:
                    st.divider()
                    if st.button(
                        "âœ… ì„¤ì • ì ìš©", use_container_width=True, type="primary"
                    ):
                        apply_config_changes()
                        st.success("ì„¤ì •ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.rerun()
                else:
                    st.divider()
                    st.caption("**í˜„ì¬ ì„¤ì •:**")
                    st.caption(f"â€¢ MMR: {'âœ…' if st.session_state.use_mmr else 'âŒ'} â€¢ Reranking: {'âœ…' if st.session_state.use_reranking else 'âŒ'} â€¢ Adaptive K: {'âœ…' if st.session_state.use_adaptive_k else 'âŒ'}")

            # ì‹œìŠ¤í…œ ê´€ë¦¬
            with st.expander("ğŸ”§ ì‹œìŠ¤í…œ ê´€ë¦¬", expanded=False):
                if st.button("ğŸ”„ ì‹œìŠ¤í…œ ì¬ì‹œì‘", help="Orchestratorë¥¼ ê°•ì œë¡œ ì¬ìƒì„±í•©ë‹ˆë‹¤", use_container_width=True):
                    st.cache_resource.clear()
                    # Create config dict for current session
                    retrieval_config = {
                        "use_mmr": st.session_state.use_mmr,
                        "use_reranking": st.session_state.use_reranking,
                        "use_adaptive_k": st.session_state.use_adaptive_k,
                        "mmr_lambda": st.session_state.mmr_lambda
                    }

                    st.session_state.orchestrator = AmbiguityAwareOrchestrator(
                        st.session_state.vectorstore_manager,
                        model_name=st.session_state.selected_model,
                        k=st.session_state.default_k,
                        verbose=False,
                        retrieval_config=retrieval_config
                    )
                    st.success("âœ… ì‹œìŠ¤í…œì´ ì¬ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()

            # ì‚¬ìš© íŒ
            with st.expander("ğŸ’¡ ì‚¬ìš© íŒ", expanded=False):
                st.markdown(
                    """
                    - ì›í•˜ëŠ” ì¥ë¥´ë‚˜ ì£¼ì œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ì£¼ì„¸ìš”
                    - "ì¶”ì²œí•´ì¤˜"ë¼ê³  ìš”ì²­í•˜ë©´ ë‹¤ì–‘í•œ ë„ì„œë¥¼ ì¶”ì²œë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
                    - íŠ¹ì • ì¹´í…Œê³ ë¦¬(ì†Œì„¤, ìê¸°ê³„ë°œ ë“±)ë¥¼ ì–¸ê¸‰í•´ë³´ì„¸ìš”
                    """
                )

        else:
            st.warning("â³ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

        # ëŒ€í™” ê¸°ë¡ ì‚­ì œ ë²„íŠ¼ (í•­ìƒ í•˜ë‹¨ì— í‘œì‹œ)
        st.divider()
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì‚­ì œ", use_container_width=True):
            st.session_state.messages = []
            # Reset agent's chat history as well
            if st.session_state.agent:
                st.session_state.agent.chat_history = []
            # Reset orchestrator state
            if st.session_state.orchestrator:
                st.session_state.orchestrator.reset_state()
            st.session_state.awaiting_clarification = False
            st.rerun()


def main():
    """Main application function."""
    # Page title
    st.title("ğŸ“š AI ë„ì„œ ì¶”ì²œ ì±—ë´‡")
    st.markdown("**RAG ê¸°ë°˜ ê°œì¸í™” ë„ì„œ ì¶”ì²œ ì‹œìŠ¤í…œ**")
    st.markdown("---")

    # Initialize session state
    initialize_session_state()

    # Initialize RAG system
    if not st.session_state.system_ready:
        vectorstore_manager, success, error = initialize_rag_system()

        if success:
            st.session_state.vectorstore_manager = vectorstore_manager

            # Initialize both agent and orchestrator
            st.session_state.agent = RAGAgent(
                vectorstore_manager,
                model_name=st.session_state.selected_model
            )
            # Create config dict for current session
            retrieval_config = {
                "use_mmr": st.session_state.use_mmr,
                "use_reranking": st.session_state.use_reranking,
                "use_adaptive_k": st.session_state.use_adaptive_k,
                "mmr_lambda": st.session_state.mmr_lambda
            }

            st.session_state.orchestrator = AmbiguityAwareOrchestrator(
                vectorstore_manager,
                model_name=st.session_state.selected_model,
                k=st.session_state.default_k,
                verbose=False,
                retrieval_config=retrieval_config
            )

            st.session_state.system_ready = True
            st.success("âœ… ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤! ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            st.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {error}")
            st.stop()

    # Display sidebar
    sidebar_settings()

    # Display chat messages
    display_chat_messages()

    # Add welcome message if no messages
    if len(st.session_state.messages) == 0:
        welcome_message = """
        ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” AI ë„ì„œ ì¶”ì²œ ì±—ë´‡ì…ë‹ˆë‹¤. ğŸ“š
        
        ì–´ë–¤ ì±…ì„ ì°¾ê³  ê³„ì‹ ê°€ìš”? ë‹¤ìŒê³¼ ê°™ì´ ì§ˆë¬¸í•´ë³´ì„¸ìš”:
        - "SF ì†Œì„¤ ì¶”ì²œí•´ì¤˜"
        - "ìê¸°ê³„ë°œ ì±… ì¤‘ì—ì„œ ì¢‹ì€ ê±° ìˆì–´?"
        - "ì—¬í–‰ ê´€ë ¨ ì±… ì¶”ì²œí•´ì¤˜"
        - "ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì¤‘ì—ì„œ ì¶”ì²œí•´ì¤˜"
        """
        with st.chat_message("assistant"):
            st.markdown(welcome_message)

    # Chat input
    if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})

        # Display user message
        with st.chat_message("user"):
            st.markdown(prompt)

        # Generate and display assistant response
        with st.chat_message("assistant"):
            with st.spinner("ìƒê°í•˜ëŠ” ì¤‘..."):
                # Choose which agent to use
                if st.session_state.use_orchestrator:
                    response_text, error, result = process_user_query(
                        prompt,
                        orchestrator=st.session_state.orchestrator
                    )
                else:
                    response_text, error, result = process_user_query(
                        prompt,
                        agent=st.session_state.agent
                    )

                if error:
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error}")
                    response_text = (
                        "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                    )

                st.markdown(response_text)

                # Show debug info if in orchestrator mode
                if st.session_state.use_orchestrator and result:
                    with st.expander("ğŸ” ì²˜ë¦¬ ê³¼ì • ì •ë³´ (ë””ë²„ê·¸)", expanded=False):
                        state = result.get("state")
                        if state:
                            st.write(f"**ëª¨í˜¸ì„± ê°ì§€**: {state.is_ambiguous}")
                            if state.is_ambiguous:
                                st.write(f"**ëª¨í˜¸ì„± ìœ í˜•**: {state.ambiguity_type}")
                                st.write(f"**ì‹ ë¢°ë„**: {state.ambiguity_confidence:.2f}")
                            if state.rewritten_query:
                                st.write(f"**ì¬ì‘ì„±ëœ ì¿¼ë¦¬**: {state.rewritten_query}")
                            st.write(f"**ê²€ìƒ‰ëœ ì±… ìˆ˜**: {len(state.retrieved_books)}")
                            if state.clarification_history:
                                st.write(f"**ëª…í™•í™” ì´ë ¥**: {len(state.clarification_history)}íšŒ")

        # Add assistant message to chat history
        st.session_state.messages.append(
            {"role": "assistant", "content": response_text}
        )


if __name__ == "__main__":
    main()
