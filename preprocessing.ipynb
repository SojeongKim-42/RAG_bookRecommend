{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89005eb3",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac80057",
   "metadata": {},
   "source": [
    "책소개, 목차가 없으면 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34176dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 파일: 대학교재_전문서적.csv ---\n",
      "초기 데이터프레임 행 수: 200\n",
      "제거된 행 수: 16\n",
      "전처리된 데이터프레임 행 수: 184\n",
      "------------------------------\n",
      "--- 파일: 만화.csv ---\n",
      "초기 데이터프레임 행 수: 200\n",
      "제거된 행 수: 71\n",
      "전처리된 데이터프레임 행 수: 129\n",
      "------------------------------\n",
      "--- 파일: 사회과학.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 799\n",
      "전처리된 데이터프레임 행 수: 200\n",
      "------------------------------\n",
      "--- 파일: 소설_시_희곡.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 800\n",
      "전처리된 데이터프레임 행 수: 199\n",
      "------------------------------\n",
      "--- 파일: 어린이.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 802\n",
      "전처리된 데이터프레임 행 수: 197\n",
      "------------------------------\n",
      "--- 파일: 에세이.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 803\n",
      "전처리된 데이터프레임 행 수: 196\n",
      "------------------------------\n",
      "--- 파일: 여행.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 801\n",
      "전처리된 데이터프레임 행 수: 198\n",
      "------------------------------\n",
      "--- 파일: 역사.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 799\n",
      "전처리된 데이터프레임 행 수: 200\n",
      "------------------------------\n",
      "--- 파일: 예술_대중문화.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 800\n",
      "전처리된 데이터프레임 행 수: 199\n",
      "------------------------------\n",
      "--- 파일: 요리_살림.csv ---\n",
      "초기 데이터프레임 행 수: 200\n",
      "제거된 행 수: 3\n",
      "전처리된 데이터프레임 행 수: 197\n",
      "------------------------------\n",
      "--- 파일: 유아.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 799\n",
      "전처리된 데이터프레임 행 수: 200\n",
      "------------------------------\n",
      "--- 파일: 인문학.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 799\n",
      "전처리된 데이터프레임 행 수: 200\n",
      "------------------------------\n",
      "--- 파일: 자기계발.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 799\n",
      "전처리된 데이터프레임 행 수: 200\n",
      "------------------------------\n",
      "--- 파일: 장르소설.csv ---\n",
      "초기 데이터프레임 행 수: 200\n",
      "제거된 행 수: 3\n",
      "전처리된 데이터프레임 행 수: 197\n",
      "------------------------------\n",
      "--- 파일: 종교_역학.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 799\n",
      "전처리된 데이터프레임 행 수: 200\n",
      "------------------------------\n",
      "--- 파일: 좋은부모.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 799\n",
      "전처리된 데이터프레임 행 수: 200\n",
      "------------------------------\n",
      "--- 파일: 청소년.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 799\n",
      "전처리된 데이터프레임 행 수: 200\n",
      "------------------------------\n",
      "전처리된 데이터가 './data/combined.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os # 파일 목록을 처리해야 할 경우를 대비해 import 합니다.\n",
    "\n",
    "def preprocess_book_data(file_path):\n",
    "    \"\"\"\n",
    "    주어진 CSV 파일에서 '책소개' 또는 '목차' 컬럼이 둘 다 결측치인 행을 제거하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): 처리할 CSV 파일의 경로.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 전처리된 데이터프레임.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 한국어 인코딩 문제로 'utf-8', 'euc-kr', 'cp949' 순으로 시도하여 파일을 읽어옵니다.\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, encoding='euc-kr')\n",
    "            except UnicodeDecodeError:\n",
    "                df = pd.read_csv(file_path, encoding='cp949')\n",
    "\n",
    "        print(f\"--- 파일: {os.path.basename(file_path)} ---\")\n",
    "        print(\"초기 데이터프레임 행 수:\", df.shape[0])\n",
    "\n",
    "        # '책소개' 또는 '목차' 컬럼 중 하나라도 결측치가 아닌(notna) 행만 선택합니다.\n",
    "        # '|' (or) 연산자를 사용하여 둘 중 하나라도 True이면 해당 행을 유지합니다.\n",
    "        # .notna()는 결측치(NaN)가 아닌 값을 True로 반환합니다.\n",
    "        cleaned_df = df[df['책소개'].notna() | df['목차'].notna()].copy()\n",
    "        \n",
    "        # float에서 int로 변환 (SettingWithCopyWarning 방지)\n",
    "        cleaned_df['ISBN13'] = cleaned_df['ISBN13'].fillna(0).astype(int)\n",
    "        cleaned_df['순번/순위'] = cleaned_df['순번/순위'].fillna(0).astype(int)\n",
    "        cleaned_df['출간일'] = cleaned_df['출간일'].fillna(0).astype(int)\n",
    "        cleaned_df['정가'] = cleaned_df['정가'].fillna(0).astype(int)\n",
    "        cleaned_df['판매가'] = cleaned_df['판매가'].fillna(0).astype(int)\n",
    "        cleaned_df['세일즈포인트'] = cleaned_df['세일즈포인트'].fillna(0).astype(int)\n",
    "\n",
    "        # ItemId, 부가기호, 마일리지 컬럼 제거\n",
    "        cleaned_df = cleaned_df.drop(columns=['ItemId', '부가기호', '마일리지'])\n",
    "\n",
    "\n",
    "        print(\"제거된 행 수:\", df.shape[0] - cleaned_df.shape[0])\n",
    "        print(\"전처리된 데이터프레임 행 수:\", cleaned_df.shape[0])\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        return cleaned_df\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"오류: 파일을 찾을 수 없습니다: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"처리 중 오류 발생: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- 사용 예시 ---\n",
    "base_path = './data'  # 데이터 파일이 위치한 디렉토리 경로\n",
    "categories = ['대학교재_전문서적', '만화', '사회과학', '소설_시_희곡', '어린이', '에세이', '여행', '역사', \n",
    "              '예술_대중문화', '요리_살림', '유아', '인문학', '자기계발', '장르소설', '종교_역학', '좋은부모', '청소년']\n",
    "\n",
    "combined = pd.DataFrame()\n",
    "\n",
    "# 모든 카테고리에 대해 전처리 수행\n",
    "for category in categories:\n",
    "    file_path = os.path.join(base_path, 'csv', f'{category}.csv')\n",
    "    cleaned_df = preprocess_book_data(file_path)\n",
    "    combined = pd.concat([combined, cleaned_df], ignore_index=True)\n",
    "\n",
    "# 전처리된 전체 데이터프레임을 하나의 CSV 파일로 저장\n",
    "output_path = os.path.join(base_path, 'combined.csv')\n",
    "combined.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"전처리된 데이터가 '{output_path}'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b9329d",
   "metadata": {},
   "source": [
    "# 특수문자 및 필요없는 문자 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c6438",
   "metadata": {},
   "source": [
    "### 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f01b7bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def clean_text(text, patterns_to_remove):\n",
    "    \"\"\"\n",
    "    텍스트에서 특정 패턴과 단어를 제거하는 함수입니다.\n",
    "    \n",
    "    Args:\n",
    "        text (str): 정제할 텍스트\n",
    "        patterns_to_remove (list): 제거할 패턴 또는 단어의 리스트\n",
    "        \n",
    "    Returns:\n",
    "        str: 정제된 텍스트\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    text = str(text)\n",
    "    for pattern in patterns_to_remove:\n",
    "        text = re.sub(pattern, '', text)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f22ecf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_chars(text, replacement_dict):\n",
    "    \"\"\"\n",
    "    텍스트에서 특정 문자를 다른 문자로 대체하는 함수입니다.\n",
    "    \n",
    "    Args:\n",
    "        text (str): 대체할 텍스트\n",
    "        replacement_dict (dict): {'기존문자': '새로운문자'} 형태의 딕셔너리\n",
    "        \n",
    "    Returns:\n",
    "        str: 대체된 텍스트\n",
    "    \n",
    "    Example:\n",
    "        replacement_dict = {'–': '-', '—': '-', '…': '...'}\n",
    "        text = \"안녕–세상–반갑습니다\"\n",
    "        result = replace_chars(text, replacement_dict)\n",
    "        # 결과: \"안녕-세상-반갑습니다\"\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    text = str(text)\n",
    "    for old_char, new_char in replacement_dict.items():\n",
    "        text = text.replace(old_char, new_char)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec39f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수문자 분석\n",
    "def find_special_chars(text, specialChars):\n",
    "    \"\"\"텍스트에서 특수문자 찾기\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return set()\n",
    "    text = str(text)\n",
    "    # 알파벳, 숫자, 한글, 공백을 제외한 모든 문자를 특수문자로 간주\n",
    "    special = re.findall(specialChars, text, re.UNICODE)\n",
    "    # special = re.findall(r'[^\\w\\s가-힣\\t!?()\\'\\\"-\\./,\\[\\]:;]', text, re.UNICODE)\n",
    "    return set(special)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c481a5",
   "metadata": {},
   "source": [
    "## 특수문자 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bebe295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발견된 특수문자 (총 0개):\n",
      "sorted(all_special_chars): []\n",
      "\n",
      "\n",
      "컬럼별 특수문자 분포:\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(base_path, 'combined_preprocessed.csv')\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "# 모든 텍스트 컬럼에서 특수문자 수집\n",
    "all_special_chars = set()\n",
    "special_char_by_column = {}\n",
    "exclude_specials = r'[^\\w\\s가-힣\\t!?()\\'\\\"-\\./,\\[\\]:;<>=@~|]'\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object' and col != '상품명':  # 텍스트 컬럼만\n",
    "        col_special_chars = set()\n",
    "        for text in df[col]:\n",
    "            col_special_chars.update(find_special_chars(text, exclude_specials))\n",
    "        special_char_by_column[col] = col_special_chars\n",
    "        all_special_chars.update(col_special_chars)\n",
    "\n",
    "print(f\"발견된 특수문자 (총 {len(all_special_chars)}개):\")\n",
    "print(f\"sorted(all_special_chars): {sorted(all_special_chars)}\")\n",
    "\n",
    "print(\"\\n\\n컬럼별 특수문자 분포:\")\n",
    "for col, chars in special_char_by_column.items():\n",
    "    if chars:  # 특수문자가 있는 컬럼만\n",
    "        print(f\"\\n{col}: {sorted(chars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215eb6a7",
   "metadata": {},
   "source": [
    "### 특이한 특수문자들 일반 특수문자로 대체하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7317b9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 대체 완료!\n",
      "선택한 단어 정제 시작...\n",
      "최종 전처리된 데이터가 './data/combined_preprocessed.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 특수문자 대체\n",
    "# 형식: {'기존문자': '새로운문자'}\n",
    "\n",
    "replacement_rules = {\n",
    "    '¿': '?',\n",
    "    '▣': '-',\n",
    "    '□': '-',\n",
    "    '▲': '-',\n",
    "    '△': '-',\n",
    "    '▶': '-',\n",
    "    '◆': '-',\n",
    "    '◇': '-',\n",
    "    '○': '-',\n",
    "    '●': '-',\n",
    "    '–': '-',      # 엔 대시를 하이픈으로\n",
    "    '—': '-',      # 이중 대시를 하이픈으로\n",
    "    '―': '-',      # 수평 대시를 하이픈으로\n",
    "    '─': '-',\n",
    "    '－': '-',\n",
    "    '＿': '-',\n",
    "    '∼': '~',\n",
    "    '∽': '~',\n",
    "    '～': '~',\n",
    "    '．': '.',\n",
    "    '。': '.', \n",
    "    '：': ':',\n",
    "    '…': '...',    # 생략 부호를 마침표 3개로\n",
    "    '，': ',',\n",
    "    '◦': '',\n",
    "    '℃': '˚C',\n",
    "    '°': '˚',\n",
    "    '㎞': 'km',   # 킬로미터 단위\n",
    "    '㎏': 'kg',\n",
    "    '∞': 'infinite',\n",
    "    '①': '1',     # 원형 숫자 1\n",
    "    '＆': '&',     # 전각 앰퍼샌드를 일반 앰퍼샌드로\n",
    "    '×': 'x',     # 곱하기 기호를 소문자 x로\n",
    "    '＝': '=',\n",
    "    '＋': '+',\n",
    "    '√': 'sqrt ',\n",
    "    '＜': '<',\n",
    "    '＞': '>',\n",
    "    '〈': '<',     # 왼쪽 꺽쇠 괄호\n",
    "    '〉': '>',     # 오른쪽 꺽쇠 괄\n",
    "    '「': '<',    # 왼쪽 일본식 큰따옴표\n",
    "    '」': '>',    # 오른쪽 일본식 큰따옴표\n",
    "    '｜': '|',\n",
    "    '│':\"|\",\n",
    "    '┃': \"|\",\n",
    "    '“': \"[\",      # 좌측 큰따옴표를 작은따옴표로\n",
    "    '”': \"]\",      # 우측 큰따옴표를 작은따옴표로\n",
    "    '‘': \"[\",      \n",
    "    '’': \"]\",\n",
    "    '´': \"'\",\n",
    "    '≪': \"[\",\n",
    "    '≫': \"]\",\n",
    "    '《': \"[\",\n",
    "    '》': \"]\", \n",
    "    '『': \"[\",\n",
    "    '』': \"]\", \n",
    "    '【': \"[\",\n",
    "    '】': \"]\",\n",
    "    '{': '[',\n",
    "    '}': ']',\n",
    "    '｢': '[',\n",
    "    '｣': ']', \n",
    "    '（': '[',\n",
    "    '）': ']',\n",
    "    '\\xad': '',    # 소프트 하이픈 제거\n",
    "    '•': '',  # 다양한 점 문자 제거\n",
    "    '·': '',  # 다양한 점 문자 제거\n",
    "    '‧': '',  # 다양한 점 문자 제거\n",
    "    '˙': '',\n",
    "    '★': '',   # 제거할 문자들\n",
    "    '☆': '',\n",
    "    '♡': '',\n",
    "    '♥': '',\n",
    "    '♪': '',\n",
    "    '♬': '',\n",
    "    'ⓒ': '',\n",
    "    '®': '',\n",
    "    'ⓔ': '',\n",
    "    'ⓘ': '',\n",
    "    '†': '',\n",
    "    '⚫': '',\n",
    "    '◎': '',\n",
    "    '↑': '',\n",
    "    '→': '',\n",
    "    '↓': '',\n",
    "    '⇔': '',\n",
    "    '≠': '!=',\n",
    "    '└': '',\n",
    "    '┗': '',\n",
    "    '＊': '',\n",
    "    '※': '',\n",
    "    '*': '',\n",
    "    '⊃': '',\n",
    "    '÷': '나누기',\n",
    "    '˚': '도',\n",
    "    '∨': '',\n",
    "    '≒': '',\n",
    "    '≤': '<=',\n",
    "    '≥': '>=',\n",
    "    '■': '',\n",
    "    '^^': '',\n",
    "    '㈜': ''\n",
    "    # 필요한 대로 더 추가할 수 있습니다\n",
    "}\n",
    "\n",
    "# 책소개 컬럼에 대체 적용\n",
    "# df['책소개'] = df['책소개'].apply(lambda x: replace_chars(x, replacement_rules))\n",
    "\n",
    "file_path = os.path.join(base_path, 'combined.csv')\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "text_columns = ['저자/아티스트', '출판사/제작사', '책소개', '목차']\n",
    "for col in text_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: replace_chars(x, replacement_rules))\n",
    "\n",
    "print(\"문자 대체 완료!\")\n",
    "\n",
    "\n",
    "# --- 선택한 단어 정제 ---\n",
    "print(\"선택한 단어 정제 시작...\")\n",
    "\n",
    "patterns = [ r'지음']\n",
    "df['출판사/제작사'] = df['출판사/제작사'].apply(\n",
    "    lambda x: clean_text(x, patterns)\n",
    ")\n",
    "\n",
    "patterns = [r'지음', r'옮김', r'그림', r'외', r'공저', r'공역', r'편저', r'엮음', r'글', r'감수']\n",
    "df['저자/아티스트'] = df['저자/아티스트'].apply(\n",
    "    lambda x: clean_text(x, patterns)\n",
    ")\n",
    "\n",
    "patterns = [r'책소개', r'미리보기']\n",
    "df['책소개'] = df['책소개'].apply(\n",
    "    lambda x: clean_text(x, patterns)\n",
    ")   \n",
    "\n",
    "patterns = [r'목차', r'\\.{2,}', r'\\_{2,}']\n",
    "df['목차'] = df['목차'].apply(\n",
    "    lambda x: clean_text(x, patterns)\n",
    ")\n",
    "\n",
    "output_path = os.path.join(base_path, 'combined_preprocessed.csv')\n",
    "df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"최종 전처리된 데이터가 '{output_path}'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cbdc39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>순번/순위</th>\n",
       "      <th>구분</th>\n",
       "      <th>상품명</th>\n",
       "      <th>ISBN13</th>\n",
       "      <th>저자/아티스트</th>\n",
       "      <th>출판사/제작사</th>\n",
       "      <th>출간일</th>\n",
       "      <th>정가</th>\n",
       "      <th>판매가</th>\n",
       "      <th>세일즈포인트</th>\n",
       "      <th>대표분류(대분류명)</th>\n",
       "      <th>책소개</th>\n",
       "      <th>목차</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>대학교재/전문서적</td>\n",
       "      <td>2026 간호사 국가고시 초단기완성 파이널 핵심요약집</td>\n",
       "      <td>9791163612827</td>\n",
       "      <td>주선희.간호수험연구소</td>\n",
       "      <td>홍지문</td>\n",
       "      <td>20251022</td>\n",
       "      <td>28000</td>\n",
       "      <td>25200</td>\n",
       "      <td>12700</td>\n",
       "      <td>수험서/자격증</td>\n",
       "      <td>2026 간호사 국가고시 초단기완성 파이널 핵심요약집은 최근 13년 동안 출제되었던...</td>\n",
       "      <td>1교시\\n1과목 성인간호학\\n1장 | 면역/신체손상\\n2장 | 안위변화\\n3장 | ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>대학교재/전문서적</td>\n",
       "      <td>이기적 유전자</td>\n",
       "      <td>9788932473901</td>\n",
       "      <td>리처드 도킨스 , 홍영남.이상임</td>\n",
       "      <td>을유문화사</td>\n",
       "      <td>20181020</td>\n",
       "      <td>20000</td>\n",
       "      <td>18000</td>\n",
       "      <td>100806</td>\n",
       "      <td>과학</td>\n",
       "      <td>과학을 넘어선 우리 시대의 고전, [이기적 유전자] 40주년 기념판\\n리처드 도킨스...</td>\n",
       "      <td>옮긴이의 말\\n30주년 기념판 서문\\n개정판 서문\\n초판 권두사\\n초판 서문\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>대학교재/전문서적</td>\n",
       "      <td>철학 에세이</td>\n",
       "      <td>9788972975168</td>\n",
       "      <td>조성오 , 이우일</td>\n",
       "      <td>동녘</td>\n",
       "      <td>20050630</td>\n",
       "      <td>14000</td>\n",
       "      <td>12600</td>\n",
       "      <td>5896</td>\n",
       "      <td>인문학</td>\n",
       "      <td>1983년 처음 출간되어 지금까지도 많은 독자들에게 인간이 부딪히는 문제에 대한 본...</td>\n",
       "      <td>다시 개정판을 내며\\n개정3판에 부쳐\\n필자의 변\\n책을 내면서\\n\\n첫째 마당|철...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>대학교재/전문서적</td>\n",
       "      <td>Do it! 점프 투 파이썬</td>\n",
       "      <td>9791163034735</td>\n",
       "      <td>박응용</td>\n",
       "      <td>이지스퍼블리싱</td>\n",
       "      <td>20230615</td>\n",
       "      <td>22000</td>\n",
       "      <td>19800</td>\n",
       "      <td>20880</td>\n",
       "      <td>컴퓨터/모바일</td>\n",
       "      <td>프로그래밍 분야 8년 연속 베스트셀러!\\n[Do it! 점프 투 파이썬] 전면 개정...</td>\n",
       "      <td>첫째마당 파이썬 기초 익히기\\n\\n01장 파이썬이란 무엇인가?\\n01-1 파이썬이란...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>대학교재/전문서적</td>\n",
       "      <td>래디컬 루만</td>\n",
       "      <td>9788961474849</td>\n",
       "      <td>한스-게오르크 묄러 , 유승무</td>\n",
       "      <td>이학사</td>\n",
       "      <td>20251105</td>\n",
       "      <td>22000</td>\n",
       "      <td>19800</td>\n",
       "      <td>2100</td>\n",
       "      <td>사회과학</td>\n",
       "      <td>20세기 가장 영향력 있는 독일 사회학자, 니클라스 루만!\\n루만의 이론에 대한 가...</td>\n",
       "      <td>서문\\n\\n1부 서론\\n\\n제1장 트로이목마: 루만의 감춰진(너무 감춰지지는 않은)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   순번/순위         구분                            상품명         ISBN13  \\\n",
       "0      1  대학교재/전문서적  2026 간호사 국가고시 초단기완성 파이널 핵심요약집  9791163612827   \n",
       "1      2  대학교재/전문서적                        이기적 유전자  9788932473901   \n",
       "2      3  대학교재/전문서적                         철학 에세이  9788972975168   \n",
       "3      4  대학교재/전문서적                Do it! 점프 투 파이썬  9791163034735   \n",
       "4      5  대학교재/전문서적                         래디컬 루만  9788961474849   \n",
       "\n",
       "             저자/아티스트  출판사/제작사       출간일     정가    판매가  세일즈포인트 대표분류(대분류명)  \\\n",
       "0        주선희.간호수험연구소      홍지문  20251022  28000  25200   12700    수험서/자격증   \n",
       "1  리처드 도킨스 , 홍영남.이상임    을유문화사  20181020  20000  18000  100806         과학   \n",
       "2          조성오 , 이우일       동녘  20050630  14000  12600    5896        인문학   \n",
       "3                박응용  이지스퍼블리싱  20230615  22000  19800   20880    컴퓨터/모바일   \n",
       "4   한스-게오르크 묄러 , 유승무      이학사  20251105  22000  19800    2100       사회과학   \n",
       "\n",
       "                                                 책소개  \\\n",
       "0  2026 간호사 국가고시 초단기완성 파이널 핵심요약집은 최근 13년 동안 출제되었던...   \n",
       "1  과학을 넘어선 우리 시대의 고전, [이기적 유전자] 40주년 기념판\\n리처드 도킨스...   \n",
       "2  1983년 처음 출간되어 지금까지도 많은 독자들에게 인간이 부딪히는 문제에 대한 본...   \n",
       "3  프로그래밍 분야 8년 연속 베스트셀러!\\n[Do it! 점프 투 파이썬] 전면 개정...   \n",
       "4  20세기 가장 영향력 있는 독일 사회학자, 니클라스 루만!\\n루만의 이론에 대한 가...   \n",
       "\n",
       "                                                  목차  \n",
       "0  1교시\\n1과목 성인간호학\\n1장 | 면역/신체손상\\n2장 | 안위변화\\n3장 | ...  \n",
       "1  옮긴이의 말\\n30주년 기념판 서문\\n개정판 서문\\n초판 권두사\\n초판 서문\\n\\n...  \n",
       "2  다시 개정판을 내며\\n개정3판에 부쳐\\n필자의 변\\n책을 내면서\\n\\n첫째 마당|철...  \n",
       "3  첫째마당 파이썬 기초 익히기\\n\\n01장 파이썬이란 무엇인가?\\n01-1 파이썬이란...  \n",
       "4  서문\\n\\n1부 서론\\n\\n제1장 트로이목마: 루만의 감춰진(너무 감춰지지는 않은)...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/combined_preprocessed.csv', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50cd77e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['순번/순위', '구분', '상품명', 'ISBN13', '저자/아티스트', '출판사/제작사', '출간일', '정가',\n",
       "       '판매가', '세일즈포인트', '대표분류(대분류명)', '책소개', '목차'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9664e380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['대학교재/전문서적', '만화', '사회과학', '소설/시/희곡', '어린이', '에세이', '여행', '역사',\n",
       "       '예술/대중문화', '요리/살림', '유아', '인문학', '자기계발', '장르소설', '종교/역학', '좋은부모',\n",
       "       '청소년'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['구분'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd67975a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['수험서/자격증', '과학', '인문학', '컴퓨터/모바일', '사회과학', '대학교재/전문서적', '경제경영',\n",
       "       '예술/대중문화', '소설/시/희곡', '외국어', '좋은부모', '역사', '만화', '에세이', '자기계발',\n",
       "       '어린이', '종교/역학', '청소년', '유아', '초등학교참고서', '여행', '요리/살림', '건강/취미',\n",
       "       '중학교참고서', '고등학교참고서'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['대표분류(대분류명)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4778b2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bkms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
