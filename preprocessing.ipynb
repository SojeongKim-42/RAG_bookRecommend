{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89005eb3",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac80057",
   "metadata": {},
   "source": [
    "책소개, 목차가 없으면 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34176dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 파일: 대학교재_전문서적.csv ---\n",
      "초기 데이터프레임 행 수: 200\n",
      "제거된 행 수: 16\n",
      "전처리된 데이터프레임 행 수: 184\n",
      "------------------------------\n",
      "--- 파일: 만화.csv ---\n",
      "초기 데이터프레임 행 수: 200\n",
      "제거된 행 수: 71\n",
      "전처리된 데이터프레임 행 수: 129\n",
      "------------------------------\n",
      "--- 파일: 사회과학.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 799\n",
      "전처리된 데이터프레임 행 수: 200\n",
      "------------------------------\n",
      "--- 파일: 소설_시_희곡.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 800\n",
      "전처리된 데이터프레임 행 수: 199\n",
      "------------------------------\n",
      "--- 파일: 어린이.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 802\n",
      "전처리된 데이터프레임 행 수: 197\n",
      "------------------------------\n",
      "--- 파일: 에세이.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 803\n",
      "전처리된 데이터프레임 행 수: 196\n",
      "------------------------------\n",
      "--- 파일: 여행.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 801\n",
      "전처리된 데이터프레임 행 수: 198\n",
      "------------------------------\n",
      "--- 파일: 역사.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 799\n",
      "전처리된 데이터프레임 행 수: 200\n",
      "------------------------------\n",
      "--- 파일: 예술_대중문화.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 800\n",
      "전처리된 데이터프레임 행 수: 199\n",
      "------------------------------\n",
      "--- 파일: 요리_살림.csv ---\n",
      "초기 데이터프레임 행 수: 200\n",
      "제거된 행 수: 3\n",
      "전처리된 데이터프레임 행 수: 197\n",
      "------------------------------\n",
      "--- 파일: 유아.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 799\n",
      "전처리된 데이터프레임 행 수: 200\n",
      "------------------------------\n",
      "--- 파일: 인문학.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 799\n",
      "전처리된 데이터프레임 행 수: 200\n",
      "------------------------------\n",
      "--- 파일: 자기계발.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 799\n",
      "전처리된 데이터프레임 행 수: 200\n",
      "------------------------------\n",
      "--- 파일: 장르소설.csv ---\n",
      "초기 데이터프레임 행 수: 200\n",
      "제거된 행 수: 3\n",
      "전처리된 데이터프레임 행 수: 197\n",
      "------------------------------\n",
      "--- 파일: 종교_역학.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 799\n",
      "전처리된 데이터프레임 행 수: 200\n",
      "------------------------------\n",
      "--- 파일: 좋은부모.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 799\n",
      "전처리된 데이터프레임 행 수: 200\n",
      "------------------------------\n",
      "--- 파일: 청소년.csv ---\n",
      "초기 데이터프레임 행 수: 999\n",
      "제거된 행 수: 799\n",
      "전처리된 데이터프레임 행 수: 200\n",
      "------------------------------\n",
      "전처리된 데이터가 './data/combined.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os # 파일 목록을 처리해야 할 경우를 대비해 import 합니다.\n",
    "\n",
    "def preprocess_book_data(file_path):\n",
    "    \"\"\"\n",
    "    주어진 CSV 파일에서 '책소개' 또는 '목차' 컬럼이 둘 다 결측치인 행을 제거하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): 처리할 CSV 파일의 경로.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 전처리된 데이터프레임.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 한국어 인코딩 문제로 'utf-8', 'euc-kr', 'cp949' 순으로 시도하여 파일을 읽어옵니다.\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, encoding='euc-kr')\n",
    "            except UnicodeDecodeError:\n",
    "                df = pd.read_csv(file_path, encoding='cp949')\n",
    "\n",
    "        print(f\"--- 파일: {os.path.basename(file_path)} ---\")\n",
    "        print(\"초기 데이터프레임 행 수:\", df.shape[0])\n",
    "\n",
    "        # '책소개' 또는 '목차' 컬럼 중 하나라도 결측치가 아닌(notna) 행만 선택합니다.\n",
    "        # '|' (or) 연산자를 사용하여 둘 중 하나라도 True이면 해당 행을 유지합니다.\n",
    "        # .notna()는 결측치(NaN)가 아닌 값을 True로 반환합니다.\n",
    "        cleaned_df = df[df['책소개'].notna() | df['목차'].notna()].copy()\n",
    "        \n",
    "        # float에서 int로 변환 (SettingWithCopyWarning 방지)\n",
    "        cleaned_df['ISBN13'] = cleaned_df['ISBN13'].fillna(0).astype(int)\n",
    "        cleaned_df['순번/순위'] = cleaned_df['순번/순위'].fillna(0).astype(int)\n",
    "        cleaned_df['출간일'] = cleaned_df['출간일'].fillna(0).astype(int)\n",
    "        cleaned_df['정가'] = cleaned_df['정가'].fillna(0).astype(int)\n",
    "        cleaned_df['판매가'] = cleaned_df['판매가'].fillna(0).astype(int)\n",
    "        cleaned_df['세일즈포인트'] = cleaned_df['세일즈포인트'].fillna(0).astype(int)\n",
    "\n",
    "        # ItemId, 부가기호, 마일리지 컬럼 제거\n",
    "        cleaned_df = cleaned_df.drop(columns=['ItemId', '부가기호', '마일리지'])\n",
    "\n",
    "\n",
    "        print(\"제거된 행 수:\", df.shape[0] - cleaned_df.shape[0])\n",
    "        print(\"전처리된 데이터프레임 행 수:\", cleaned_df.shape[0])\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        return cleaned_df\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"오류: 파일을 찾을 수 없습니다: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"처리 중 오류 발생: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- 사용 예시 ---\n",
    "base_path = './data'  # 데이터 파일이 위치한 디렉토리 경로\n",
    "categories = ['대학교재_전문서적', '만화', '사회과학', '소설_시_희곡', '어린이', '에세이', '여행', '역사', \n",
    "              '예술_대중문화', '요리_살림', '유아', '인문학', '자기계발', '장르소설', '종교_역학', '좋은부모', '청소년']\n",
    "\n",
    "combined = pd.DataFrame()\n",
    "\n",
    "# 모든 카테고리에 대해 전처리 수행\n",
    "for category in categories:\n",
    "    file_path = os.path.join(base_path, 'csv', f'{category}.csv')\n",
    "    cleaned_df = preprocess_book_data(file_path)\n",
    "    combined = pd.concat([combined, cleaned_df], ignore_index=True)\n",
    "\n",
    "# 전처리된 전체 데이터프레임을 하나의 CSV 파일로 저장\n",
    "output_path = os.path.join(base_path, 'combined.csv')\n",
    "combined.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"전처리된 데이터가 '{output_path}'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b9329d",
   "metadata": {},
   "source": [
    "# 특수문자 및 필요없는 문자 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c6438",
   "metadata": {},
   "source": [
    "### 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f01b7bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def clean_text(text, patterns_to_remove):\n",
    "    \"\"\"\n",
    "    텍스트에서 특정 패턴과 단어를 제거하는 함수입니다.\n",
    "    \n",
    "    Args:\n",
    "        text (str): 정제할 텍스트\n",
    "        patterns_to_remove (list): 제거할 패턴 또는 단어의 리스트\n",
    "        \n",
    "    Returns:\n",
    "        str: 정제된 텍스트\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    text = str(text)\n",
    "    for pattern in patterns_to_remove:\n",
    "        text = re.sub(pattern, '', text)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f22ecf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_chars(text, replacement_dict):\n",
    "    \"\"\"\n",
    "    텍스트에서 특정 문자를 다른 문자로 대체하는 함수입니다.\n",
    "    \n",
    "    Args:\n",
    "        text (str): 대체할 텍스트\n",
    "        replacement_dict (dict): {'기존문자': '새로운문자'} 형태의 딕셔너리\n",
    "        \n",
    "    Returns:\n",
    "        str: 대체된 텍스트\n",
    "    \n",
    "    Example:\n",
    "        replacement_dict = {'–': '-', '—': '-', '…': '...'}\n",
    "        text = \"안녕–세상–반갑습니다\"\n",
    "        result = replace_chars(text, replacement_dict)\n",
    "        # 결과: \"안녕-세상-반갑습니다\"\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    text = str(text)\n",
    "    for old_char, new_char in replacement_dict.items():\n",
    "        text = text.replace(old_char, new_char)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec39f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수문자 분석\n",
    "def find_special_chars(text, specialChars):\n",
    "    \"\"\"텍스트에서 특수문자 찾기\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return set()\n",
    "    text = str(text)\n",
    "    # 알파벳, 숫자, 한글, 공백을 제외한 모든 문자를 특수문자로 간주\n",
    "    special = re.findall(specialChars, text, re.UNICODE)\n",
    "    # special = re.findall(r'[^\\w\\s가-힣\\t!?()\\'\\\"-\\./,\\[\\]:;]', text, re.UNICODE)\n",
    "    return set(special)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c481a5",
   "metadata": {},
   "source": [
    "## 특수문자 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bebe295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발견된 특수문자 (총 0개):\n",
      "sorted(all_special_chars): []\n",
      "\n",
      "\n",
      "컬럼별 특수문자 분포:\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(base_path, 'combined_preprocessed.csv')\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "# 모든 텍스트 컬럼에서 특수문자 수집\n",
    "all_special_chars = set()\n",
    "special_char_by_column = {}\n",
    "exclude_specials = r'[^\\w\\s가-힣\\t!?()\\'\\\"-\\./,\\[\\]:;<>=@~|]'\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object' and col != '상품명':  # 텍스트 컬럼만\n",
    "        col_special_chars = set()\n",
    "        for text in df[col]:\n",
    "            col_special_chars.update(find_special_chars(text, exclude_specials))\n",
    "        special_char_by_column[col] = col_special_chars\n",
    "        all_special_chars.update(col_special_chars)\n",
    "\n",
    "print(f\"발견된 특수문자 (총 {len(all_special_chars)}개):\")\n",
    "print(f\"sorted(all_special_chars): {sorted(all_special_chars)}\")\n",
    "\n",
    "print(\"\\n\\n컬럼별 특수문자 분포:\")\n",
    "for col, chars in special_char_by_column.items():\n",
    "    if chars:  # 특수문자가 있는 컬럼만\n",
    "        print(f\"\\n{col}: {sorted(chars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215eb6a7",
   "metadata": {},
   "source": [
    "### 특이한 특수문자들 일반 특수문자로 대체하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7317b9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 대체 완료!\n",
      "선택한 단어 정제 시작...\n",
      "최종 전처리된 데이터가 './data/combined_preprocessed.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 특수문자 대체\n",
    "# 형식: {'기존문자': '새로운문자'}\n",
    "\n",
    "replacement_rules = {\n",
    "    '¿': '?',\n",
    "    '▣': '-',\n",
    "    '□': '-',\n",
    "    '▲': '-',\n",
    "    '△': '-',\n",
    "    '▶': '-',\n",
    "    '◆': '-',\n",
    "    '◇': '-',\n",
    "    '○': '-',\n",
    "    '●': '-',\n",
    "    '–': '-',      # 엔 대시를 하이픈으로\n",
    "    '—': '-',      # 이중 대시를 하이픈으로\n",
    "    '―': '-',      # 수평 대시를 하이픈으로\n",
    "    '─': '-',\n",
    "    '－': '-',\n",
    "    '＿': '-',\n",
    "    '∼': '~',\n",
    "    '∽': '~',\n",
    "    '～': '~',\n",
    "    '．': '.',\n",
    "    '。': '.', \n",
    "    '：': ':',\n",
    "    '…': '...',    # 생략 부호를 마침표 3개로\n",
    "    '，': ',',\n",
    "    '◦': '',\n",
    "    '℃': '˚C',\n",
    "    '°': '˚',\n",
    "    '㎞': 'km',   # 킬로미터 단위\n",
    "    '㎏': 'kg',\n",
    "    '∞': 'infinite',\n",
    "    '①': '1',     # 원형 숫자 1\n",
    "    '＆': '&',     # 전각 앰퍼샌드를 일반 앰퍼샌드로\n",
    "    '×': 'x',     # 곱하기 기호를 소문자 x로\n",
    "    '＝': '=',\n",
    "    '＋': '+',\n",
    "    '√': 'sqrt ',\n",
    "    '＜': '<',\n",
    "    '＞': '>',\n",
    "    '〈': '<',     # 왼쪽 꺽쇠 괄호\n",
    "    '〉': '>',     # 오른쪽 꺽쇠 괄\n",
    "    '「': '<',    # 왼쪽 일본식 큰따옴표\n",
    "    '」': '>',    # 오른쪽 일본식 큰따옴표\n",
    "    '｜': '|',\n",
    "    '│':\"|\",\n",
    "    '┃': \"|\",\n",
    "    '“': \"[\",      # 좌측 큰따옴표를 작은따옴표로\n",
    "    '”': \"]\",      # 우측 큰따옴표를 작은따옴표로\n",
    "    '‘': \"[\",      \n",
    "    '’': \"]\",\n",
    "    '´': \"'\",\n",
    "    '≪': \"[\",\n",
    "    '≫': \"]\",\n",
    "    '《': \"[\",\n",
    "    '》': \"]\", \n",
    "    '『': \"[\",\n",
    "    '』': \"]\", \n",
    "    '【': \"[\",\n",
    "    '】': \"]\",\n",
    "    '{': '[',\n",
    "    '}': ']',\n",
    "    '｢': '[',\n",
    "    '｣': ']', \n",
    "    '（': '[',\n",
    "    '）': ']',\n",
    "    '\\xad': '',    # 소프트 하이픈 제거\n",
    "    '•': '',  # 다양한 점 문자 제거\n",
    "    '·': '',  # 다양한 점 문자 제거\n",
    "    '‧': '',  # 다양한 점 문자 제거\n",
    "    '˙': '',\n",
    "    '★': '',   # 제거할 문자들\n",
    "    '☆': '',\n",
    "    '♡': '',\n",
    "    '♥': '',\n",
    "    '♪': '',\n",
    "    '♬': '',\n",
    "    'ⓒ': '',\n",
    "    '®': '',\n",
    "    'ⓔ': '',\n",
    "    'ⓘ': '',\n",
    "    '†': '',\n",
    "    '⚫': '',\n",
    "    '◎': '',\n",
    "    '↑': '',\n",
    "    '→': '',\n",
    "    '↓': '',\n",
    "    '⇔': '',\n",
    "    '≠': '!=',\n",
    "    '└': '',\n",
    "    '┗': '',\n",
    "    '＊': '',\n",
    "    '※': '',\n",
    "    '*': '',\n",
    "    '⊃': '',\n",
    "    '÷': '나누기',\n",
    "    '˚': '도',\n",
    "    '∨': '',\n",
    "    '≒': '',\n",
    "    '≤': '<=',\n",
    "    '≥': '>=',\n",
    "    '■': '',\n",
    "    '^^': '',\n",
    "    '㈜': ''\n",
    "    # 필요한 대로 더 추가할 수 있습니다\n",
    "}\n",
    "\n",
    "# 책소개 컬럼에 대체 적용\n",
    "# df['책소개'] = df['책소개'].apply(lambda x: replace_chars(x, replacement_rules))\n",
    "\n",
    "file_path = os.path.join(base_path, 'combined.csv')\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "text_columns = ['저자/아티스트', '출판사/제작사', '책소개', '목차']\n",
    "for col in text_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: replace_chars(x, replacement_rules))\n",
    "\n",
    "print(\"문자 대체 완료!\")\n",
    "\n",
    "\n",
    "# --- 선택한 단어 정제 ---\n",
    "print(\"선택한 단어 정제 시작...\")\n",
    "\n",
    "patterns = [ r'지음']\n",
    "df['출판사/제작사'] = df['출판사/제작사'].apply(\n",
    "    lambda x: clean_text(x, patterns)\n",
    ")\n",
    "\n",
    "patterns = [r'지음', r'옮김', r'그림', r'외', r'공저', r'공역', r'편저', r'엮음', r'글', r'감수']\n",
    "df['저자/아티스트'] = df['저자/아티스트'].apply(\n",
    "    lambda x: clean_text(x, patterns)\n",
    ")\n",
    "\n",
    "patterns = [r'책소개', r'미리보기']\n",
    "df['책소개'] = df['책소개'].apply(\n",
    "    lambda x: clean_text(x, patterns)\n",
    ")   \n",
    "\n",
    "patterns = [r'목차', r'\\.{2,}', r'\\_{2,}']\n",
    "df['목차'] = df['목차'].apply(\n",
    "    lambda x: clean_text(x, patterns)\n",
    ")\n",
    "\n",
    "output_path = os.path.join(base_path, 'combined_preprocessed.csv')\n",
    "df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"최종 전처리된 데이터가 '{output_path}'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbdc39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67975a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bkms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
